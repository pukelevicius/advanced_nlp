{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142c2df5-2011-4aa1-8e70-9f91f22e0371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3036f8-a126-443b-9ceb-a8be7a5d5ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global parameters:\n",
    "BASELINE = True # True for baseline model, false for advanced\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MULTILABEL = True\n",
    "\n",
    "if MULTILABEL:\n",
    "    task = 'argument-classification' # multilabel\n",
    "else:\n",
    "    task = 'argument-identification' # binary\n",
    "    \n",
    "if BASELINE:\n",
    "    model_type = 'baseline'\n",
    "else:\n",
    "    model_type = 'advanced'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79476835-931e-4dbb-acdb-7e14262a9c29",
   "metadata": {},
   "source": [
    "Importing data and applying transformation for conll format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bd1f75-2921-483d-bdab-49f97378ad92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '../Data/en_ewt-up-train.conllu'\n",
    "dev_path = '../Data/en_ewt-up-dev.conllu'\n",
    "test_path = '../Data/en_ewt-up-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d5a4ea-13b9-4577-9092-8efad3c29243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = conll_transform(read_conll(train_path))\n",
    "dev_data = conll_transform(read_conll(dev_path))\n",
    "test_data = conll_transform(read_conll(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e582a1f7-5ff6-4a58-addb-bb69251bac2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_predicate_argument_feats(df):\n",
    "    \"\"\"\n",
    "    Fuction to extract argument and predicate features from transformed\n",
    "    conll format data.\n",
    "    \n",
    "    params:\n",
    "    df: Dataframe of transformed conll data\n",
    "    \"\"\"\n",
    "    # feature to indicate if the token is a predicate; maybe redundant\n",
    "    df['is_token_predicate'] = (df['predicate'] != '_').astype(int)\n",
    "    # feature for classification task 1: argument identification\n",
    "    df['is_token_argument'] = (df['argument_type'].str.startswith('ARG')).astype(int)\n",
    "    # feature for classification task 2: argument classification\n",
    "    df['argument_label'] = df['argument_type'].apply(lambda x: x if x.startswith('ARG') else 'O')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d849f54-9373-4770-aa3a-39d3dae68704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = extract_predicate_argument_feats(train_data)\n",
    "dev_data = extract_predicate_argument_feats(dev_data)\n",
    "test_data = extract_predicate_argument_feats(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c3ea96-8bee-4c15-befd-36693d8f476e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get rid of unnecessary columns\n",
    "train_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)\n",
    "dev_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)\n",
    "test_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de865a46-a0c5-4c8e-a664-b1c08e86b2df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'argument-classification'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568c79ba-81b8-4d8e-b140-4053b5a363db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARGM-LVB', 'ARGM-ADV', 'ARG2', 'ARGA', 'ARGM-DIR', 'ARG5', 'O', 'ARGM-REC', 'ARGM-DIS', 'ARGM-LOC', 'ARG4', 'ARGM-CXN', 'ARGM-PRR', 'ARGM-ADJ', 'ARGM-MNR', 'ARGM-GOL', 'ARG1', 'ARGM-COM', 'ARGM-CAU', 'ARGM-PRD', 'ARGM-TMP', 'ARG3', 'ARGM-MOD', 'ARGM-EXT', 'ARGM-PRP', 'ARG0', 'ARG1-DSP', 'ARGM-NEG'}\n"
     ]
    }
   ],
   "source": [
    "if task == 'argument-identification':\n",
    "    label_list = set(train_data['is_token_argument'].tolist())\n",
    "    print(label_list)\n",
    "elif task == 'argument-classification':\n",
    "    label_list = set(train_data['argument_label'].tolist())\n",
    "    # for mapping str labels to int:\n",
    "    label_mapping = {}\n",
    "    for e, label in enumerate(label_list):\n",
    "        label_mapping.update({label: int(e)})\n",
    "    print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac6d4d-5f3d-43d1-aa28-f50a36bc2741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0096154-3811-4eeb-a22b-e8e0f489a986",
   "metadata": {},
   "source": [
    "Following function represents each sentence data (tokens, predicate/argument labels, etc) to lists, therefore,\n",
    "info of each distinct sentence will be stored in designated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6255296e-444f-4a45-813f-15091ec44b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent setence in a list:\n",
    "def extract_sentences(df: pd.DataFrame, baseline=True):\n",
    "    \"\"\"\n",
    "    extracts sentences from \n",
    "    \"\"\"\n",
    "    model_type = 'baseline' if baseline else 'advanced'  \n",
    "    \n",
    "    sentences = []\n",
    "    arguments = []\n",
    "    arg_label = []\n",
    "    sentence_ids = []\n",
    "    \n",
    "    current_sent = []\n",
    "    current_sent_arguments = []\n",
    "    current_sent_arg_label = []\n",
    "    \n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['token_id'] == '1' and current_sent:\n",
    "            if model_type == 'baseline':\n",
    "                # add everything for baseline predicate mark at the end of sentence\n",
    "                current_sent.append('[SEP]')\n",
    "                current_sent.append(predicate_token)\n",
    "                current_sent_arguments.append(-100)\n",
    "                current_sent_arguments.append(-100)\n",
    "                current_sent_arg_label.append(-100)\n",
    "                current_sent_arg_label.append(-100)\n",
    "\n",
    "            \n",
    "            sentences.append(current_sent)\n",
    "            arguments.append(current_sent_arguments)\n",
    "            arg_label.append(current_sent_arg_label)\n",
    "            sentence_ids.append(current_id)\n",
    "            \n",
    "            current_sent = []\n",
    "            current_sent_arguments = []\n",
    "            current_sent_arg_label = []\n",
    "        \n",
    "        if model_type == 'baseline': \n",
    "            if row['is_token_predicate'] == 1:\n",
    "                predicate_token = row['token']\n",
    "        \n",
    "            current_sent.append(row['token'])\n",
    "            current_sent_arguments.append(row['is_token_argument'])\n",
    "            current_sent_arg_label.append(label_mapping[row['argument_label']])\n",
    "            current_id = row['sent_id']\n",
    "            \n",
    "        elif model_type == 'advanced':\n",
    "            \n",
    "            if row['is_token_predicate'] == 1:\n",
    "                # adding special token '[PREDICATE]' before predicate for advanced model\n",
    "                current_sent.append('[PREDICATE]')\n",
    "                current_sent.append(row['token'])\n",
    "                current_sent_arguments.append(-100)\n",
    "                current_sent_arguments.append(row['is_token_argument'])\n",
    "                current_sent_arg_label.append(-100)\n",
    "                current_sent_arg_label.append(label_mapping[row['argument_label']])\n",
    "                \n",
    "            else:\n",
    "                current_sent.append(row['token'])\n",
    "                current_sent_arguments.append(row['is_token_argument'])\n",
    "                current_sent_arg_label.append(label_mapping[row['argument_label']])\n",
    "                current_id = row['sent_id']\n",
    "           \n",
    "    return sentences, arguments, arg_label, sentence_ids  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3753fa64-ba8f-42ff-bfd6-8ee114a6539c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents,  arguments, arg_label, sentence_ids = extract_sentences(train_data, baseline=BASELINE)\n",
    "\n",
    "# Create a new DataFrame with the grouped data\n",
    "formatted_train = pd.DataFrame({\n",
    "    'sentence_id': sentence_ids,\n",
    "    'sentences': sents,\n",
    "    'is_argument': arguments, # binary - is_argument\n",
    "    'arg_labels': arg_label # multilabel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6402c8bd-0187-49c8-9409-238248c87d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents,  arguments, arg_label, sentence_ids = extract_sentences(dev_data, baseline=BASELINE)\n",
    "\n",
    "# Create a new DataFrame with the grouped data\n",
    "formatted_dev = pd.DataFrame({\n",
    "    'sentence_id': sentence_ids,\n",
    "    'sentences': sents,\n",
    "    'is_argument': arguments, # binary - is_argument\n",
    "    'arg_labels': arg_label # multilabel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74f9785b-8157-4907-935a-1c14cb3e05dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents,  arguments, arg_label, sentence_ids = extract_sentences(test_data, baseline=BASELINE)\n",
    "\n",
    "# Create a new DataFrame with the grouped data\n",
    "formatted_test = pd.DataFrame({\n",
    "    'sentence_id': sentence_ids,\n",
    "    'sentences': sents,\n",
    "    'is_argument': arguments, # binary - is_argument\n",
    "    'arg_labels': arg_label # multilabel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19b85671-9a75-4b71-86a0-148f9e2af7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>is_argument</th>\n",
       "      <th>arg_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[Al, -, Zaman, :, American, forces, killed, Sh...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 25, 6, 16, 6, 6, 6, 6, 6, 6, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[[, This, killing, of, a, respected, cleric, w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 16, 6, 6, 6, 6, 6, 6, 6, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[DPA, :, Iraqi, authorities, announced, that, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 6, 6, 25, 6, 6, 6, 6, 16, 6, 6, 6, 6, 6, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[Two, of, them, were, being, run, by, 2, offic...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[The, MoI, in, Iraq, is, equivalent, to, the, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 16, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence_id  \\\n",
       "0  weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "1  weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "2  weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "3  weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "4  weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Al, -, Zaman, :, American, forces, killed, Sh...   \n",
       "1  [[, This, killing, of, a, respected, cleric, w...   \n",
       "2  [DPA, :, Iraqi, authorities, announced, that, ...   \n",
       "3  [Two, of, them, were, being, run, by, 2, offic...   \n",
       "4  [The, MoI, in, Iraq, is, equivalent, to, the, ...   \n",
       "\n",
       "                                         is_argument  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          arg_labels  \n",
       "0  [6, 6, 6, 6, 6, 25, 6, 16, 6, 6, 6, 6, 6, 6, 6...  \n",
       "1  [6, 6, 6, 6, 6, 6, 16, 6, 6, 6, 6, 6, 6, 6, 6,...  \n",
       "2  [6, 6, 6, 25, 6, 6, 6, 6, 16, 6, 6, 6, 6, 6, 6...  \n",
       "3  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "4  [6, 16, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6,...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70510176-b651-4717-83f5-625271d2906c",
   "metadata": {},
   "source": [
    "Saving processed to csv because running all cells sequentially exhausts all of the system ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d7fdbc0-adc6-46d1-b110-b4bfce8bfc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formatted_train.to_csv(f'../Data/transformers_formatted_train_{model_type}.csv', index=False)\n",
    "formatted_dev.to_csv(f'../Data/transformers_formatted_dev_{model_type}.csv', index=False)\n",
    "formatted_test.to_csv(f'../Data/transformers_formatted_test_{model_type}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b708338-ab02-44de-894f-adfd656e31ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formatted_train = pd.read_csv(f'../Data/transformers_formatted_train_{model_type}.csv')\n",
    "formatted_dev = pd.read_csv(f'../Data/transformers_formatted_dev_{model_type}.csv')\n",
    "formatted_test = pd.read_csv(f'../Data/transformers_formatted_test_{model_type}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6914e0cf-4151-461d-a15a-2cefcb1f60e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the list columns are read as strings by pd.read_csv, thus converting it back to lists\n",
    "formatted_train = fix_lists(formatted_train)\n",
    "formatted_dev = fix_lists(formatted_dev)\n",
    "formatted_test = fix_lists(formatted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed132232-2ef2-4b1a-bb34-150e3dcc86f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# adding special token for advanced model:\n",
    "if BASELINE == False:   \n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['[PREDICATE]']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f04fbae-8422-44e6-bdd5-1b8846657901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(data, multilabel, label_all_tokens = True):\n",
    "    \"\"\"\n",
    "    Tokenizes the input examples and aligns argument labels and ids.\n",
    "\n",
    "    Parameters:\n",
    "    data: DataFrame containing tokens, sentence IDs, and argument labels/ids.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of new examples with tokenized inputs and aligned labels.\n",
    "    \"\"\"\n",
    "    sentence_lists = data['sentences'].tolist()\n",
    "    sentence_ids = data['sentence_id'].tolist()\n",
    "    \n",
    "    # Tokenize sentences:\n",
    "    tokenized_inputs = tokenizer(sentence_lists, truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    aligned_examples = []\n",
    "    \n",
    "    for i, (is_arg, arg_label) in enumerate(zip(data['is_argument'], data['arg_labels'])):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        arg_ids = []\n",
    "        labels = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                arg_ids.append(-100)\n",
    "                labels.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                arg_ids.append(is_arg[word_idx])\n",
    "                labels.append(arg_label[word_idx])\n",
    "            else:\n",
    "                arg_ids.append(is_arg[word_idx] if label_all_tokens else -100)\n",
    "                labels.append(arg_label[word_idx] if label_all_tokens else -100)\n",
    "            \n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        if multilabel:\n",
    "            aligned_examples.append({\n",
    "                'sentence_id': sentence_ids[i],\n",
    "                'sentence': sentence_lists[i],\n",
    "                'word_ids': word_ids,\n",
    "                'input_ids': tokenized_inputs['input_ids'][i],\n",
    "                'attention_mask': tokenized_inputs['attention_mask'][i],\n",
    "                'labels': labels,\n",
    "            })\n",
    "        else:\n",
    "            aligned_examples.append({\n",
    "                'sentence_id': sentence_ids[i],\n",
    "                'sentence': sentence_lists[i],\n",
    "                'word_ids': word_ids,\n",
    "                'input_ids': tokenized_inputs['input_ids'][i],\n",
    "                'attention_mask': tokenized_inputs['attention_mask'][i],\n",
    "                'labels': arg_ids,\n",
    "            })\n",
    "            \n",
    "    return aligned_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77acd3f4-beb3-440c-8f8d-22f59f27fe59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train = tokenize_and_align_labels(formatted_train, MULTILABEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3d5eac8-cb70-4228-bcf5-8b306bcc5499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dev = tokenize_and_align_labels(formatted_dev, MULTILABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f171dc77-d9e2-4ef2-8044-1218b3d50ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_test = tokenize_and_align_labels(formatted_test, MULTILABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea3fc875-e097-447c-90f8-e8d1f4b6dc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41474\n",
      "5307\n",
      "5210\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_train))\n",
    "print(len(tokenized_dev))\n",
    "print(len(tokenized_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "482056f8-4ab8-477d-8666-28a43a9d566d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence_id', 'sentence', 'word_ids', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d9a1a-9e24-4016-9782-52ff532ffb1e",
   "metadata": {},
   "source": [
    "argument identifcation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7fec4d3-255f-4f7c-9181-500daba12c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
    "# making sure that special token is added:\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "767db67c-7345-4967-a13b-36441df19974",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"{MODEL_NAME}-finetuned-{model_type}-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c570310-28b6-4364-b117-80d81d8b2474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac224278-0d87-4ac6-ad1c-49f06a27967e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "839a5be0-6b61-4482-9baa-0117acfc0791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2593' max='2593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2593/2593 04:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.275986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2593, training_loss=0.28737434860917993, metrics={'train_runtime': 279.8188, 'train_samples_per_second': 148.217, 'train_steps_per_second': 9.267, 'total_flos': 740693836646400.0, 'train_loss': 0.28737434860917993, 'epoch': 1.0})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7929022-4b2a-414c-b9d8-93cc6df5c5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_subtoken_logits(tokenized_data, predictions):\n",
    "    \"\"\"\n",
    "    Aggregates subtoken logits to word level for each example in a tokenized dataset.\n",
    "\n",
    "    Parameters:\n",
    "    tokenized_data: A list of tokenized data, where each list is a dictionary containing\n",
    "                               'sentence' and 'word_ids'.\n",
    "    predictions: A list of subtoken-level predictions, corresponding to the tokenized examples.\n",
    "                        Each element in the list is an array of logits for an example.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of word-level logits for each example. Each element in the list is an array of aggregated logits,\n",
    "          corresponding to the words in the example.\n",
    "    \"\"\"\n",
    "    word_level_logits = []\n",
    "\n",
    "    for index, data in enumerate(tokenized_data):\n",
    "        tokens = data['sentence']\n",
    "        word_ids = data['word_ids']\n",
    "        subtoken_logits = np.array(predictions[index])\n",
    "        current_word_id = None\n",
    "        current_word_logits = None\n",
    "        sentence_logits = []\n",
    "\n",
    "        for subtoken_index, word_id in enumerate(word_ids):\n",
    "            if word_id is not None and word_id != current_word_id:\n",
    "                if current_word_logits is not None:\n",
    "                    sentence_logits.append(current_word_logits)\n",
    "\n",
    "                current_word_id = word_id\n",
    "                current_word_logits = subtoken_logits[subtoken_index].copy()\n",
    "            elif word_id is not None:\n",
    "                current_word_logits += subtoken_logits[subtoken_index]\n",
    "\n",
    "        if current_word_logits is not None:\n",
    "            sentence_logits.append(current_word_logits)\n",
    "\n",
    "        word_level_logits.append(np.array(sentence_logits))\n",
    "\n",
    "    return word_level_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaf63c7b-0096-4ae2-bac3-0b94329a9547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_labels_with_predictions(tokenized_data):\n",
    "    \"\"\"\n",
    "    Aligns original labels with their corresponding word-level predictions in tokenized data.\n",
    "\n",
    "    Parameters:\n",
    "    tokenized_data: A list of tokenized examples, where each example is a dictionary containing\n",
    "                           'word_ids' and 'labels'. 'word_ids' should be a list of word IDs for each subtoken,\n",
    "                           and 'labels' should be a list of labels for each subtoken.\n",
    "\n",
    "    Returns:\n",
    "    list: A list where each element is a list of aligned labels for the words in the corresponding tokenized example.\n",
    "    \"\"\"\n",
    "    aligned_labels = []\n",
    "\n",
    "    for item in tokenized_data:\n",
    "        # Extract word IDs and labels, ignoring special tokens at the start and end\n",
    "        word_ids = item['word_ids'][1:-1]\n",
    "        original_labels = item['labels'][1:-1]\n",
    "\n",
    "        # Aggregate labels based on word IDs\n",
    "        current_word_id = None\n",
    "        word_labels = []\n",
    "\n",
    "        for word_id, label in zip(word_ids, original_labels):\n",
    "            if word_id is not None and word_id != current_word_id:\n",
    "                # Start of a new word\n",
    "                word_labels.append(label)\n",
    "                current_word_id = word_id\n",
    "\n",
    "        aligned_labels.append(word_labels)\n",
    "\n",
    "    return aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e28b38a1-2608-4cbe-82eb-c9ad104cd312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = trainer.predict(tokenized_test)\n",
    "test_preds = test_predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a542abfc-9232-4cc7-bda0-5841c953846b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregatted_test_preds = aggregate_subtoken_logits(tokenized_test, test_preds)\n",
    "aggregatted_test_preds = [np.argmax(pred, axis=1) for pred in aggregatted_test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5b13eeb-c943-48a0-9712-92bef58e2522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6, 16,  6,  6,  6,  6,  6,  6])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregatted_test_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc595488-9b16-4b7d-bbb5-a83ac419fa83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_true_test_labels = align_labels_with_predictions(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3da3e2ae-2a1c-4e62-8f8a-2640995247f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 16, 6, 6, 2, 6, -100, -100]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_true_test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5babbb73-4152-4f6d-b145-94a8debf4480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_baseline_indexes(predictions, labels, label_list):    \n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return true_predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c03b12ab-5c9f-49ae-859b-dac11a34a940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MULTILABEL:\n",
    "    preds, true_labels = remove_baseline_indexes(aggregatted_test_preds, aligned_true_test_labels, \n",
    "                                                 label_list=list(label_mapping.values()))\n",
    "else:\n",
    "    preds, true_labels = remove_baseline_indexes(aggregatted_test_preds, aligned_true_test_labels, \n",
    "                                                 label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40ce05fc-c129-40d3-9883-4bf9953f8920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def calculate_classification_metrics(preds, true_labels, multilabel):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, f1 score, and macro average metrics for classification results.\n",
    "    \n",
    "    Parameters:\n",
    "    preds: List of list of predictions from token classification\n",
    "    true_labels: List of list of true labels from token classification\n",
    "    return: \n",
    "    Dictionary with precision, recall, f1 score for each class and macro averages\n",
    "    \"\"\"\n",
    "    # Flatten the predictions and true labels lists\n",
    "    preds_flat = [p for sublist in preds for p in sublist]\n",
    "    true_flat = [t for sublist in true_labels for t in sublist]\n",
    "    \n",
    "    # Extract unique classes\n",
    "    if multilabel:\n",
    "        classes = list(label_mapping.values())\n",
    "    else:\n",
    "        classes = sorted(set(true_flat))\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_flat, preds_flat, labels=classes)\n",
    "    \n",
    "    # Calculate macro averages\n",
    "    precision_macro = np.mean(precision)\n",
    "    recall_macro = np.mean(recall)\n",
    "    f1_macro = np.mean(f1)\n",
    "    \n",
    "    # Create a dictionary to store the metrics\n",
    "    metrics = {\n",
    "        'classes': label_list if multilabel else classes,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'macro': {\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "becc05c2-a72c-4572-bddf-550d8a25d3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results = calculate_classification_metrics(preds, true_labels, MULTILABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0df58239-1963-41ed-9d90-b3844ce1408c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'ARG0',\n",
       "  'ARG1',\n",
       "  'ARG1-DSP',\n",
       "  'ARG2',\n",
       "  'ARG3',\n",
       "  'ARG4',\n",
       "  'ARG5',\n",
       "  'ARGA',\n",
       "  'ARGM-ADJ',\n",
       "  'ARGM-ADV',\n",
       "  'ARGM-CAU',\n",
       "  'ARGM-COM',\n",
       "  'ARGM-CXN',\n",
       "  'ARGM-DIR',\n",
       "  'ARGM-DIS',\n",
       "  'ARGM-EXT',\n",
       "  'ARGM-GOL',\n",
       "  'ARGM-LOC',\n",
       "  'ARGM-LVB',\n",
       "  'ARGM-MNR',\n",
       "  'ARGM-MOD',\n",
       "  'ARGM-NEG',\n",
       "  'ARGM-PRD',\n",
       "  'ARGM-PRP',\n",
       "  'ARGM-PRR',\n",
       "  'ARGM-REC',\n",
       "  'ARGM-TMP',\n",
       "  'O'},\n",
       " 'precision': array([0.        , 0.55263158, 0.62303665, 0.        , 0.        ,\n",
       "        0.        , 0.9243318 , 0.        , 0.61842105, 0.6875    ,\n",
       "        0.        , 0.        , 0.        , 0.75      , 0.5       ,\n",
       "        0.        , 0.65750286, 0.        , 0.        , 0.        ,\n",
       "        0.68965517, 0.        , 0.67213115, 0.84615385, 0.33333333,\n",
       "        0.62363239, 0.        , 0.5625    ]),\n",
       " 'recall': array([0.        , 0.04393305, 0.10788758, 0.        , 0.        ,\n",
       "        0.        , 0.9930507 , 0.        , 0.26256983, 0.05583756,\n",
       "        0.        , 0.        , 0.        , 0.15207373, 0.02816901,\n",
       "        0.        , 0.18204884, 0.        , 0.        , 0.        ,\n",
       "        0.11560694, 0.        , 0.28873239, 0.1047619 , 0.01333333,\n",
       "        0.17076093, 0.        , 0.25714286]),\n",
       " 'f1': array([0.        , 0.08139535, 0.18392581, 0.        , 0.        ,\n",
       "        0.        , 0.95745981, 0.        , 0.36862745, 0.10328638,\n",
       "        0.        , 0.        , 0.        , 0.25287356, 0.05333333,\n",
       "        0.        , 0.28514655, 0.        , 0.        , 0.        ,\n",
       "        0.1980198 , 0.        , 0.40394089, 0.18644068, 0.02564103,\n",
       "        0.26810913, 0.        , 0.35294118]),\n",
       " 'macro': {'precision_macro': 0.3228867796438873,\n",
       "  'recall_macro': 0.09913959567017046,\n",
       "  'f1_macro': 0.1328978908287972}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cd0c309a-87ac-483b-ac74-6f9863bb162d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dict_to_json(results, f'../Results/{MODEL_NAME}-{model_type}-results.json')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
