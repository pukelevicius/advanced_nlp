{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "142c2df5-2011-4aa1-8e70-9f91f22e0371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88bd1f75-2921-483d-bdab-49f97378ad92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '../Data/en_ewt-up-train.conllu'\n",
    "dev_path = '../Data/en_ewt-up-dev.conllu'\n",
    "test_path = '../Data/en_ewt-up-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8d5a4ea-13b9-4577-9092-8efad3c29243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = conll_transform(read_conll(train_path))\n",
    "dev_data = conll_transform(read_conll(dev_path))\n",
    "test_data = conll_transform(read_conll(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e582a1f7-5ff6-4a58-addb-bb69251bac2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_predicate_argument_feats(df):\n",
    "\n",
    "    # feature to indicate if the token is a predicate; maybe redundant\n",
    "    df['is_token_predicate'] = (df['predicate'] != '_').astype(int)\n",
    "    # feature for classification task 1: argument identification\n",
    "    df['is_token_argument'] = (df['argument_type'].str.startswith('ARG')).astype(int)\n",
    "    # feature for classification task 2: argument classification\n",
    "    df['argument_label'] = df['argument_type'].apply(lambda x: x if x.startswith('ARG') else 'O')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d849f54-9373-4770-aa3a-39d3dae68704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = extract_predicate_argument_feats(train_data)\n",
    "dev_data = extract_predicate_argument_feats(dev_data)\n",
    "test_data = extract_predicate_argument_feats(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51c3ea96-8bee-4c15-befd-36693d8f476e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)\n",
    "dev_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)\n",
    "test_data.drop(['lemma', 'POS','morph_type','distance_head','dep_label','dep_rel'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6255296e-444f-4a45-813f-15091ec44b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent setence in a list:\n",
    "def extract_sentences(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    extracts sentences from \n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    predicates = []\n",
    "    arguments = []\n",
    "    arg_label = []\n",
    "    sentence_ids = []\n",
    "    \n",
    "    current_sent = []\n",
    "    current_sent_predicates = []\n",
    "    current_sent_arguments = []\n",
    "    current_sent_arg_label = []\n",
    "    \n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['token_id'] == '1' and current_sent:\n",
    "            # add baseline mark for predicate\n",
    "            current_sent.append(baseline_mark)\n",
    "            \n",
    "            sentences.append(current_sent)\n",
    "            predicates.append(current_sent_predicates)\n",
    "            arguments.append(current_sent_arguments)\n",
    "            arg_label.append(current_sent_arg_label)\n",
    "            sentence_ids.append(current_id)\n",
    "            \n",
    "            current_sent = []\n",
    "            current_sent_predicates = []\n",
    "            current_sent_arguments = []\n",
    "            current_sent_arg_label = []\n",
    "        \n",
    "        if row['is_token_predicate'] == 1:\n",
    "            baseline_mark = '[SEP] ' + row['token']\n",
    "        \n",
    "        current_sent.append(row['token'])\n",
    "        current_sent_predicates.append(row['is_token_predicate'])\n",
    "        current_sent_arguments.append(row['is_token_argument'])\n",
    "        current_sent_arg_label.append(row['argument_label'])\n",
    "        current_id = row['sent_id']\n",
    "    \n",
    "           \n",
    "    return sentences, predicates, arguments, arg_label, sentence_ids  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3753fa64-ba8f-42ff-bfd6-8ee114a6539c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents, predicates, arguments, arg_label, sentence_ids = extract_sentences(train_data)\n",
    "\n",
    "# Create a new DataFrame with the grouped data\n",
    "formatted_train = pd.DataFrame({\n",
    "    'sentence_id': sentence_ids,\n",
    "    'sentences': sents,\n",
    "    'is_predicate': predicates, # binary - is_predicate\n",
    "    'is_argument': arguments, # binary - is_argument\n",
    "    'arg_labels': arg_label # multilabel\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "643109a9-05fe-4731-bb3b-2bbc8c37aa86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>is_predicate</th>\n",
       "      <th>is_argument</th>\n",
       "      <th>arg_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[Al, -, Zaman, :, American, forces, killed, Sh...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, ARG0, O, ARG1, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[[, This, killing, of, a, respected, cleric, w...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, ARG1, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[DPA, :, Iraqi, authorities, announced, that, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, ARG0, O, O, O, O, ARG1, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[Two, of, them, were, being, run, by, 2, offic...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "      <td>[The, MoI, in, Iraq, is, equivalent, to, the, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, ARG1, O, O, O, ARG2, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41469</th>\n",
       "      <td>reviews-319816-0028</td>\n",
       "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, ARG1, O, ARGM-NEG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41470</th>\n",
       "      <td>reviews-319816-0028</td>\n",
       "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, ARG1, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41471</th>\n",
       "      <td>reviews-319816-0028</td>\n",
       "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41472</th>\n",
       "      <td>reviews-319816-0028</td>\n",
       "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41473</th>\n",
       "      <td>reviews-319816-0029</td>\n",
       "      <td>[I, will, never, return, there, again, (, and,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, ARGM-PRR,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41474 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence_id  \\\n",
       "0      weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "1      weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "2      weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "3      weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "4      weblog-juancole.com_juancole_20051126063000_EN...   \n",
       "...                                                  ...   \n",
       "41469                                reviews-319816-0028   \n",
       "41470                                reviews-319816-0028   \n",
       "41471                                reviews-319816-0028   \n",
       "41472                                reviews-319816-0028   \n",
       "41473                                reviews-319816-0029   \n",
       "\n",
       "                                               sentences  \\\n",
       "0      [Al, -, Zaman, :, American, forces, killed, Sh...   \n",
       "1      [[, This, killing, of, a, respected, cleric, w...   \n",
       "2      [DPA, :, Iraqi, authorities, announced, that, ...   \n",
       "3      [Two, of, them, were, being, run, by, 2, offic...   \n",
       "4      [The, MoI, in, Iraq, is, equivalent, to, the, ...   \n",
       "...                                                  ...   \n",
       "41469  [The, employees, at, this, Sear's, are, comple...   \n",
       "41470  [The, employees, at, this, Sear's, are, comple...   \n",
       "41471  [The, employees, at, this, Sear's, are, comple...   \n",
       "41472  [The, employees, at, this, Sear's, are, comple...   \n",
       "41473  [I, will, never, return, there, again, (, and,...   \n",
       "\n",
       "                                            is_predicate  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "3       [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "...                                                  ...   \n",
       "41469  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...   \n",
       "41470  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...   \n",
       "41471  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...   \n",
       "41472  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, ...   \n",
       "41473  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                             is_argument  \\\n",
       "0      [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "41469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...   \n",
       "41470  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "41471  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41472  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "41473  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                              arg_labels  \n",
       "0      [O, O, O, O, O, ARG0, O, ARG1, O, O, O, O, O, ...  \n",
       "1      [O, O, O, O, O, O, ARG1, O, O, O, O, O, O, O, ...  \n",
       "2      [O, O, O, ARG0, O, O, O, O, ARG1, O, O, O, O, ...  \n",
       "3       [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4      [O, ARG1, O, O, O, ARG2, O, O, O, O, O, O, O, ...  \n",
       "...                                                  ...  \n",
       "41469  [O, O, O, O, O, O, O, O, O, ARG1, O, ARGM-NEG,...  \n",
       "41470  [O, O, O, O, O, O, O, O, O, ARG1, O, O, O, O, ...  \n",
       "41471  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "41472  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "41473  [O, O, O, O, O, O, O, O, O, O, O, O, ARGM-PRR,...  \n",
       "\n",
       "[41474 rows x 5 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed132232-2ef2-4b1a-bb34-150e3dcc86f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f95ac2e236401ba4b7163f11729aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ab314ed1d24084beffefdc649c7988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b42108f055a4bcd9cb511d47c30ef93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442ae0ac97dd496d8ea67c656f4cffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7819fb12-cfc5-479d-b2fd-d02b39a41285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22d78a3b-ad49-4ca7-9913-bae7c6853087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 102, 2253, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('I [SEP] went')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cab4e5e9-9bd1-4e87-a562-cd717af6677a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 102, 102, 2253, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([['I', '[SEP] went']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d1023e2-1bd1-41eb-b597-ac8e9d8bc078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 102, 102], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[SEP]')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
