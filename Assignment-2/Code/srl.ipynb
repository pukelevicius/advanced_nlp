{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_utils import *\n",
    "from feature_utils import *\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../Data/en_ewt-up-train.conllu'\n",
    "dev_path = '../Data/en_ewt-up-dev.conllu'\n",
    "test_path = '../Data/en_ewt-up-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data(train_path)\n",
    "dev_data = prepare_data(dev_path)\n",
    "test_data = prepare_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1011069, 32), (103886, 32), (100431, 32))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, dev_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_data = read_conll(train_path)\\ntrain_slice = train_data[train_data['sent_id'] == 'weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002']\\ntrain_ex = conll_transform(train_slice)\\n#train_ex.to_csv('train_ex.csv', sep='\\t', index=False)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the following code to see if the conll transform works\n",
    "# select a sample sentence from train data\n",
    "'''\n",
    "train_data = read_conll(train_path)\n",
    "train_slice = train_data[train_data['sent_id'] == 'weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0002']\n",
    "train_ex = conll_transform(train_slice)\n",
    "#train_ex.to_csv('train_ex.csv', sep='\\t', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Universal_POS</th>\n",
       "      <th>morph_type</th>\n",
       "      <th>distance_head</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>dep_rel</th>\n",
       "      <th>...</th>\n",
       "      <th>token_bigram</th>\n",
       "      <th>POS_bigram</th>\n",
       "      <th>token_trigram</th>\n",
       "      <th>POS_trigram</th>\n",
       "      <th>ner</th>\n",
       "      <th>distance_to_predicate</th>\n",
       "      <th>is_before_predicate</th>\n",
       "      <th>is_token_predicate</th>\n",
       "      <th>is_token_argument</th>\n",
       "      <th>argument_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answers-20090605110235AAALlCt_ans-0001</td>\n",
       "      <td>1</td>\n",
       "      <td>Where</td>\n",
       "      <td>where</td>\n",
       "      <td>ADV</td>\n",
       "      <td>WRB</td>\n",
       "      <td>PronType=Int</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>...</td>\n",
       "      <td>_ Where</td>\n",
       "      <td>_ ADV</td>\n",
       "      <td>_ _ Where</td>\n",
       "      <td>_ _ ADV</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ARG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answers-20090605110235AAALlCt_ans-0001</td>\n",
       "      <td>2</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>...</td>\n",
       "      <td>Where in</td>\n",
       "      <td>ADV ADP</td>\n",
       "      <td>_ Where in</td>\n",
       "      <td>_ ADV ADP</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answers-20090605110235AAALlCt_ans-0001</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>4</td>\n",
       "      <td>det</td>\n",
       "      <td>4:det</td>\n",
       "      <td>...</td>\n",
       "      <td>in the</td>\n",
       "      <td>ADP DET</td>\n",
       "      <td>Where in the</td>\n",
       "      <td>ADV ADP DET</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>answers-20090605110235AAALlCt_ans-0001</td>\n",
       "      <td>4</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>1</td>\n",
       "      <td>obl</td>\n",
       "      <td>1:obl:in</td>\n",
       "      <td>...</td>\n",
       "      <td>the world</td>\n",
       "      <td>DET NOUN</td>\n",
       "      <td>in the world</td>\n",
       "      <td>ADP DET NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answers-20090605110235AAALlCt_ans-0001</td>\n",
       "      <td>5</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>1</td>\n",
       "      <td>cop</td>\n",
       "      <td>1:cop</td>\n",
       "      <td>...</td>\n",
       "      <td>world is</td>\n",
       "      <td>NOUN AUX</td>\n",
       "      <td>the world is</td>\n",
       "      <td>DET NOUN AUX</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sent_id  token_id  token  lemma   POS  \\\n",
       "0  answers-20090605110235AAALlCt_ans-0001         1  Where  where   ADV   \n",
       "1  answers-20090605110235AAALlCt_ans-0001         2     in     in   ADP   \n",
       "2  answers-20090605110235AAALlCt_ans-0001         3    the    the   DET   \n",
       "3  answers-20090605110235AAALlCt_ans-0001         4  world  world  NOUN   \n",
       "4  answers-20090605110235AAALlCt_ans-0001         5     is     be   AUX   \n",
       "\n",
       "  Universal_POS                                         morph_type  \\\n",
       "0           WRB                                       PronType=Int   \n",
       "1            IN                                                  _   \n",
       "2            DT                          Definite=Def|PronType=Art   \n",
       "3            NN                                        Number=Sing   \n",
       "4           VBZ  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...   \n",
       "\n",
       "  distance_head dep_label   dep_rel  ... token_bigram POS_bigram  \\\n",
       "0             0      root    0:root  ...      _ Where      _ ADV   \n",
       "1             4      case    4:case  ...     Where in    ADV ADP   \n",
       "2             4       det     4:det  ...       in the    ADP DET   \n",
       "3             1       obl  1:obl:in  ...    the world   DET NOUN   \n",
       "4             1       cop     1:cop  ...     world is   NOUN AUX   \n",
       "\n",
       "  token_trigram   POS_trigram ner distance_to_predicate is_before_predicate  \\\n",
       "0     _ _ Where       _ _ ADV   O                     2                   1   \n",
       "1    _ Where in     _ ADV ADP   O                     2                   1   \n",
       "2  Where in the   ADV ADP DET   O                     1                   1   \n",
       "3  in the world  ADP DET NOUN   O                     1                   1   \n",
       "4  the world is  DET NOUN AUX   O                     1                   0   \n",
       "\n",
       "  is_token_predicate is_token_argument  argument_label  \n",
       "0                  0                 1            ARG2  \n",
       "1                  0                 0               O  \n",
       "2                  0                 0               O  \n",
       "3                  0                 0               O  \n",
       "4                  1                 0               O  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARG2', 'O', 'ARG1', 'ARGM-MNR', 'ARGM-ADV', 'ARGM-LOC',\n",
       "       'ARGM-MOD', 'ARGM-ADJ', 'ARG0', 'ARGM-DIR', 'ARGM-DIS', 'ARGM-CAU',\n",
       "       'ARGM-TMP', 'ARGM-PRD', 'ARGM-GOL', 'ARGM-EXT', 'ARGM-NEG',\n",
       "       'ARGM-CXN', 'ARG3', 'ARG4', 'ARGM-PRP', 'ARGM-PRR', 'ARGM-LVB',\n",
       "       'ARGM-COM', 'ARG5', 'ARGA', 'ARGM-REC', 'ARG1-DSP'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['argument_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1011069, 227226)\n",
      "Shape of y_train_encoded_array: (1011069, 30)\n",
      "Shape of X_test: (100431, 227226)\n",
      "Shape of y_dev_encoded_array: (100431, 30)\n"
     ]
    }
   ],
   "source": [
    "target = ['is_token_argument', 'argument_label']\n",
    "\n",
    "numeric_features = ['definite_ind', 'number_plur', 'gender_fem', 'case_nom', 'tense_pres',\n",
    "                     'mood_ind', 'verbform', 'voice_passive', 'possesive', 'pron_type', 'person']\n",
    "\n",
    "text_features = ['token', 'lemma', 'POS', 'Universal_POS', 'morph_type', 'dep_label', 'dep_rel',\n",
    "                  'space', 'predicate', 'ner', 'token_bigram', 'token_trigram', 'POS_bigram', 'POS_trigram']\n",
    "\n",
    "count_vectorizer = create_count_vectorizer(train_data, text_features)\n",
    "X_train = process_data(train_data, count_vectorizer, numeric_features)\n",
    "X_test = process_data(test_data, count_vectorizer, numeric_features)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train_encoded = encoder.fit_transform(train_data[target])\n",
    "y_dev_encoded = encoder.transform(test_data[target])\n",
    "y_train = y_train_encoded.toarray()\n",
    "y_test = y_dev_encoded.toarray()\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train_encoded_array:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_dev_encoded_array:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=0))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Arugment Identification:\n",
      "Weighted Average Precision: 0.8935\n",
      "Weighted Average Recall: 0.9155\n",
      "Weighted Average F1-Score: 0.8896\n",
      "\n",
      "Macro Average Precision: 0.7637\n",
      "Macro Average Recall: 0.5606\n",
      "Macro Average F1-Score: 0.5843\n",
      "------------------------------\n",
      "\n",
      "For Argument Classification:\n",
      "Weighted Average Precision: 0.9920\n",
      "Weighted Average Recall: 0.9942\n",
      "Weighted Average F1-Score: 0.9921\n",
      "\n",
      "Macro Average Precision: 0.5929\n",
      "Macro Average Recall: 0.5205\n",
      "Macro Average F1-Score: 0.5269\n"
     ]
    }
   ],
   "source": [
    "weighted_avg_precision_identification, weighted_avg_recall_identification, weighted_avg_f1_identification,\\\n",
    "    macro_avg_precision_identification, macro_avg_recall_identification, macro_avg_f1_identification = calculate_metrics(0, 2, y_test, y_pred)\n",
    "print(\"For Arugment Identification:\")\n",
    "print(f\"Weighted Average Precision: {weighted_avg_precision_identification:.4f}\")\n",
    "print(f\"Weighted Average Recall: {weighted_avg_recall_identification:.4f}\")\n",
    "print(f\"Weighted Average F1-Score: {weighted_avg_f1_identification:.4f}\\n\")\n",
    "print(f\"Macro Average Precision: {macro_avg_precision_identification:.4f}\")\n",
    "print(f\"Macro Average Recall: {macro_avg_recall_identification:.4f}\")\n",
    "print(f\"Macro Average F1-Score: {macro_avg_f1_identification:.4f}\")\n",
    "\n",
    "print(\"---\"*10)\n",
    "\n",
    "weighted_avg_precision_classification, weighted_avg_recall_classification, weighted_avg_f1_classification,\\\n",
    "      macro_avg_precision_classification, macro_avg_recall_classification, macro_avg_f1_classification = calculate_metrics(3, 30, y_test, y_pred)\n",
    "print(\"\\nFor Argument Classification:\")\n",
    "print(f\"Weighted Average Precision: {weighted_avg_precision_classification:.4f}\")\n",
    "print(f\"Weighted Average Recall: {weighted_avg_recall_classification:.4f}\")\n",
    "print(f\"Weighted Average F1-Score: {weighted_avg_f1_classification:.4f}\\n\")\n",
    "print(f\"Macro Average Precision: {macro_avg_precision_classification:.4f}\")\n",
    "print(f\"Macro Average Recall: {macro_avg_recall_classification:.4f}\")\n",
    "print(f\"Macro Average F1-Score: {macro_avg_f1_classification:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
